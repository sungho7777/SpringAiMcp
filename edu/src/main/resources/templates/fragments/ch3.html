<!DOCTYPE html>
<html lang="ko" xmlns:th="http://www.thymeleaf.org">

<th:block>


    <h1>Chapter 3. Advisor API</h1><br>

    <h2>1. Core Components</h2>

    <p>
        Spring AI의 <strong>Advisors API</strong>는 애플리케이션 내부에서 AI 모델과의 상호작용을 가로채고
        변환하며 보강할 수 있도록 설계된 고급 확장 프레임워크입니다.
        이를 통해 공통적인 생성형 AI 처리 로직을 캡슐화하고,
        입·출력 흐름을 정교하게 제어하며, 재사용 가능한 AI 컴포넌트를 구성할 수 있습니다.
    </p>

    <p>Advisor API의 주요 장점은 다음과 같습니다:</p>

    <ul>
        <li>반복되는 생성형 AI 패턴을 재사용 가능한 모듈로 캡슐화</li>
        <li>LLM 입·출력 데이터를 구조적으로 가공 및 변환</li>
        <li>다양한 AI 모델과 도메인에서 일관된 확장성 제공</li>
        <li>요청(Request)과 응답(Response)을 모두 인터셉트하여 전·후처리 가능</li>
    </ul>

    <h3>예시 코드</h3>

    <pre><code>SimpleLoggerAdvisor customLogger = new SimpleLoggerAdvisor(
        request -&gt; "[SimpleLoggerAdvisor] Custom request: "
                + request.prompt().getUserMessage(),
        response -&gt; "[SimpleLoggerAdvisor] Custom response: "
                + response.getResult(),
        Ordered.HIGHEST_PRECEDENCE);

SafeGuardAdvisor safeGuardAdvisor = new SafeGuardAdvisor(
        List.of("스미싱", "무기", "비밀번호"),
        "사용자의 입력에 금지된 단어가 포함되어 있어 요청을 처리할 수 없습니다.",
        Ordered.HIGHEST_PRECEDENCE);

this.chatClient = chatClientBuilder
        .defaultAdvisors(customLogger, new CheckCharSizeAdvisor(), safeGuardAdvisor)
        .build();
</code></pre>

    <p>
        Spring AI는 요청 처리 시 <code>ChatClientRequest</code>와 <code>Prompt</code> 객체를 생성하며,
        각 Advisor는 요청/응답을 수정하거나 흐름을 차단할 수 있습니다.
        체인의 마지막 Advisor가 실제 <strong>Chat Model</strong>에 요청을 전송하고,
        모델의 응답은 다시 역방향 체인을 거쳐 최종적으로 <code>ChatClientResponse</code>로 반환됩니다.
    </p>
    <img th:src="@{/imgs/advisor1.png}" width="600px;"><br><a href="https://docs.spring.io/spring-ai/reference/api/advisors.html">출처:docs.springai.io</a><br><br>

    <p>
        또한 Spring AI는 비스트리밍(non-streaming) 시나리오에서는
        <code>CallAdvisor</code> 기반 동작을 사용하고,
        스트리밍(streaming) 시나리오에서는 Reactor <code>Flux</code> 기반 스트림 처리 방식을 적용합니다.
    </p>
    <hr>

    <h2>2. Advisor Order</h2>

    <p>
        Advisor의 실행 순서는 각 Advisor가 정의하는 <code>getOrder()</code> 값에 의해 결정됩니다.
        다음 규칙이 적용됩니다:
    </p>
    <img th:src="@{/imgs/advisor2.png}" width="600px;"><br><a href="https://docs.spring.io/spring-ai/reference/api/advisors.html">출처:docs.springai.io</a><br><br>

    <ul>
        <li><strong>요청 처리(Request)</strong>: 낮은 getOrder() 값이 먼저 실행</li>
        <li><strong>응답 처리(Response)</strong>: 요청 처리의 역순(스택 구조)</li>
    </ul>

    <p>
        정리하면 다음과 같습니다:
    </p>

    <ul>
        <li><code>Ordered.HIGHEST_PRECEDENCE</code> → 요청 시 최우선 실행, 응답 시 마지막 실행</li>
        <li><code>Ordered.LOWEST_PRECEDENCE</code> → 요청 시 마지막 실행, 응답 시 최우선 실행</li>
        <li>동일 우선순위는 실행 순서를 보장하지 않음</li>
    </ul>

    <p>
        이 구조를 통해 Advisor 체인 전체에서 단계적 필터링, 전처리, 후처리가 가능하며
        공통 로직을 체계적으로 모듈화할 수 있습니다.
    </p>
    <span><a href="https://docs.spring.io/spring-ai/reference/api/advisors.html">SpringAi 참고</a></span>
    <hr>

    <h2>3. Streaming vs Non-Streaming</h2>

    <p>
        Spring AI Advisor는 두 가지 실행 모델을 지원합니다:
    </p>
    <img th:src="@{/imgs/advisor3.png}" width="600px;"><br><a href="https://docs.spring.io/spring-ai/reference/api/advisors.html">출처:docs.springai.io</a><br><br>

    <ul>
        <li><strong>Non-Streaming (비스트리밍)</strong>: 요청·응답 완성 객체 단위 처리.
            전통적인 REST 및 단일 응답 모델에 적합</li>
        <li><strong>Streaming (스트리밍)</strong>: Reactor <code>Flux</code> 기반 메시지 스트림 처리.
            대용량 텍스트 생성 및 지속적 출력에서 유리</li>
    </ul>

    <p>
        스트리밍 방식은 응답을 여러 chunk 단위로 점진적으로 가공할 수 있어
        실시간 처리 시나리오에서 강력한 유연성을 제공합니다.
    </p>


</th:block>

</html>